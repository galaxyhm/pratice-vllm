{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galaxyhm/pratice-vllm/blob/main/VLLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Package"
      ],
      "metadata": {
        "id": "AWnDJeGrM_gC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfAR3IQ1DwtY",
        "outputId": "092e31a9-2466-4b1c-a458-766900208e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.3/217.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.5/227.5 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pycountry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.1.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m499.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.16.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Collecting torchtext==0.16.0+cpu\n",
            "  Downloading https://download.pytorch.org/whl/torchtext-0.16.0%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16.0+cpu) (4.66.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0) (2.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0+cu121) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0+cu121) (1.3.0)\n",
            "Installing collected packages: torch, torchvision, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu118\n",
            "    Uninstalling torchvision-0.16.0+cu118:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu118\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.16.0\n",
            "    Uninstalling torchtext-0.16.0:\n",
            "      Successfully uninstalled torchtext-0.16.0\n",
            "Successfully installed torch-2.1.0+cu121 torchtext-0.16.0+cpu torchvision-0.16.0+cu121\n"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade fschat accelerate autoawq vllm\n",
        "!pip install torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio==2.1.0 torchtext==0.16.0+cpu torchdata==0.7.0 --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "model_id = \"TheBloke/Llama-2-7b-Chat-AWQ\""
      ],
      "metadata": {
        "id": "DN81o61MFMBR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "iF2WIxUoEEyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395bf2c0-5372-47c0-d31e-c184ed93ad67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING 12-01 07:04:47 config.py:140] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
            "INFO 12-01 07:04:47 llm_engine.py:72] Initializing an LLM engine with config: model='TheBloke/Llama-2-7b-Chat-AWQ', tokenizer='TheBloke/Llama-2-7b-Chat-AWQ', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=awq, seed=0)\n",
            "INFO 12-01 07:04:47 tokenizer.py:31] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
            "INFO 12-01 07:05:15 llm_engine.py:207] # GPU blocks: 1018, # CPU blocks: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 4/4 [00:09<00:00,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: 'Hello, my name is', Generated text: \" Sherry and I'm a 35-year-old woman from the United States. I've been a vegetarian for over 15 years and I'm passionate about living a healthy and sustainable lifestyle. I believe that food is not just fuel for our bodies, but also a way to nourish our minds and souls.\\nI've been following a vegan diet for the past 5 years and I'm excited to share my experiences and tips with you. From simple meals like tofu stir-fries and lentil soups, to more elaborate dishes like vegan pizza and pasta, I'll be sharing recipes and ideas that are easy to make and delicious to eat.\\nI'll also be discussing the benefits of a vegan lifestyle, including improved health, reduced environmental impact, and the ethical considerations of raising and killing animals for food. I believe that everyone can benefit from a plant-based diet, and I'm excited to share my knowledge and enthusiasm with you.\\nSo, whether you're a fellow vegan or just starting to explore the world of plant-based eating,\"\n",
            "Prompt: 'The president of the United States is', Generated text: ' the head of the executive branch of the federal government. The president is elected by the people through the electoral college and serves a four-year term. The president is responsible for executing the laws passed by Congress and is the commander-in-chief of the armed forces. The president also has the power to negotiate treaties and appoint federal judges, ambassadors, and other high-ranking officials.\\n\\n\\n\\n\\n\\n\\n'\n",
            "Prompt: 'The capital of France is', Generated text: ' Paris.\\n It is located in the northern central part of the country and is the largest city in France.\\n\\n Paris is known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, Notre-Dame Cathedral, and the Arc de Triomphe.\\n It is also famous for its fashion, cuisine, and art.\\nThe city has a rich history dating back to the 3rd century BC and has been ruled by various empires and dynasties throughout the centuries.\\nToday, Paris is a popular tourist destination and is home to many international organizations such as UNESCO and the OECD.\\n\\n\\n\\n\\n'\n",
            "Prompt: 'The future of AI is', Generated text: ' bright, but it also raises many ethical concerns. Here are some of the ethical issues that AI raises:\\n\\n1. Bias: AI systems can perpetuate and even amplify existing biases if they are trained on biased data or designed with biased algorithms. This can lead to unfair outcomes, such as discrimination against certain groups of people.\\n2. Privacy: AI systems often rely on collecting and processing large amounts of personal data, which raises concerns about privacy and data protection. Who controls this data, and how is it used?\\n3. Job displacement: AI has the potential to automate many jobs, which could lead to significant job displacement and unemployment. This could have serious social and economic implications.\\n4. Transparency and explainability: AI systems can be complex and difficult to understand, making it challenging to determine how they make decisions. This lack of transparency and explainability can make it difficult to hold AI systems accountable for their actions.\\n5. Autonomous weapons: The development of autonomous weapons, such as drones and other lethal autonomous robots, raises significant'\n",
            "걸린시간은 9.14초\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "# Sample prompts.\n",
        "prompts = [\n",
        "    \"Hello, my name is\",\n",
        "    \"The president of the United States is\",\n",
        "    \"The capital of France is\",\n",
        "    \"The future of AI is\",\n",
        "]\n",
        "# Create a sampling params object.\n",
        "sampling_params = SamplingParams(temperature=0.5, top_p=0.95, max_tokens=256)\n",
        "\n",
        "# Create an LLM.\n",
        "llm = LLM(model=model_id, quantization=\"AWQ\")\n",
        "# Generate texts from the prompts. The output is a list of RequestOutput objects\n",
        "# that contain the prompt, generated text, and other information.\n",
        "start_time = time.time()\n",
        "outputs = llm.generate(prompts, sampling_params)\n",
        "# Print the outputs.\n",
        "for output in outputs:\n",
        "    prompt = output.prompt\n",
        "    generated_text = output.outputs[0].text\n",
        "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")\n",
        "end_time = time.time()\n",
        "print(f\"걸린시간은 {end_time-start_time:.2f}초\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Memory clear\n",
        "\n",
        "from vllm import LLM, SamplingParams\n",
        "import gc\n",
        "import torch\n",
        "from vllm.model_executor.parallel_utils.parallel_state import destroy_model_parallel\n",
        "destroy_model_parallel()\n",
        "#del llm\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZiHTt51aFdox"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id,  device_map=\"cuda:0\")\n",
        "tokenizer= AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "YAAbN4n8T5D9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myparams ={\n",
        "    \"temperature\":0.8,\n",
        "    \"top_p\": 0.95,\n",
        "    \"max_new_tokens\" : 256,\n",
        "\n",
        "}\n",
        "start_time = time.time()\n",
        "#input_id = tokenizer.encode(prompts, return_tensors=\"pt\").to('cuda')\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "encoding = tokenizer(prompts, return_tensors='pt',padding=True).to('cuda')\n",
        "#output = model.generate(input_id, eos_token_id=tokenizer.eos_token_id,**myparams)\n",
        "generated_ids = model.generate(**encoding, **myparams)\n",
        "generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "for text in generated_texts:\n",
        "  print(text)\n",
        "  print('\\n')\n",
        "end_time = time.time()\n",
        "print(f\"걸린시간은 {end_time-start_time:.2f}초\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9phv3FSeQsnj",
        "outputId": "c652ff2c-7e7a-4850-9251-76210ecbc3d8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, my name is Mirella, and I am an Italian woman living in the United States. I have been married to my husband, John, for 25 years, and we have two adult children, Michael and Sarah.\n",
            "Growing up in Italy, I was always taught to be strong and independent. My family was poor, but we always made do with what we had. My mother was a hard worker, and she instilled in me the value of hard work and determination. I remember her always telling me, \"Mirella, you can do anything you set your mind to.\"\n",
            "When I met John, he was working in New York City, and I was living in Italy. We met through mutual friends, and we immediately hit it off. We started dating long-distance, and after a year, John proposed to me. I was 23 years old at the time.\n",
            "We got married in Italy, and then we moved to New York City. It was a big change for me, but John was always there to support me. He helped me learn English, and he introduced me to American culture.\n",
            "Over the years, we had two children, Michael and Sarah. Raising them was a challenge, but it was\n",
            "1\n",
            "The president of the United States is the highest-ranking official in the executive branch and is one of the most powerful people in the world. The president is elected by the people through the Electoral College and serves a four-year term. The president's duties include:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. Serving as the commander-in-chief of the armed forces\n",
            "2. Nominating and, with the advice and consent of the Senate, appointing federal judges, including Supreme Court justices\n",
            "3. Signing or vetoing bills passed by Congress\n",
            "4. Conducting foreign policy and negotiating treaties on behalf of the United States\n",
            "5. Appointing ambassadors and other high-ranking officials\n",
            "6. Making executive orders, which have the force of law\n",
            "7. Addressing the nation and Congress on important issues\n",
            "8. Leading the federal government's response to natural disasters and other emergencies\n",
            "9. Granting pardons to individuals convicted of federal crimes\n",
            "10. Serving as the symbol of the nation and representing the United States on the world stage.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The president also has a number of ceremonial duties, including:\n",
            "\n",
            "1\n",
            "The capital of France is Paris. A city located in the northern central part of the country, Paris is known for its stunning architecture, rich history, and cultural attractions. The city is home to many famous landmarks such as the Eiffel Tower, the Louvre Museum, and Notre Dame Cathedral.\n",
            "Paris is also a hub for fashion, art, and gastronomy, with many world-renowned designers and chefs calling the city home. The city has a vibrant cultural scene, with numerous theaters, museums, and festivals throughout the year.\n",
            "In addition to its cultural attractions, Paris is also known for its beautiful parks and gardens, including the Luxembourg Gardens and the Tuileries Garden. The city is also home to many famous squares, such as the Place de la Concorde and the Place des Vosges.\n",
            "Paris has a long and storied history, dating back to the 3rd century when it was a small Gallo-Roman settlement. Over the centuries, the city grew and became an important center of trade and commerce, eventually becoming the capital of France in 508 AD. Today, Paris is one of the most popular tourist destinations in\n",
            "1\n",
            "The future of AI is expected to have a significant impact on various industries, including healthcare, finance, transportation, and education. Here are some potential developments and trends that could shape the future of AI:\n",
            "1. Increased Adoption: As AI technologies become more mature and accessible, more businesses and industries are likely to adopt them, leading to increased use cases and applications.\n",
            "2. Expansion of AI into new domains: AI will increasingly be applied to new domains such as climate change, agriculture, and urban planning.\n",
            "3. Continued Advances in Deep Learning: Deep learning, a subset of machine learning, is expected to continue to drive many of the recent breakthroughs in AI.\n",
            "4. Increased Focus on Explainability and Interpretability: As AI systems become more pervasive, there will be a growing need for explainability and interpretability of AI decisions, leading to the development of new techniques and tools.\n",
            "5. Ethical and Social Implications: As AI becomes more powerful and widespread, there will be a growing need for ethical and social considerations around its development and deployment, such as privacy\n",
            "1\n",
            "걸린시간은 14.10초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 일반처리\n",
        "myparams ={\n",
        "    \"temperature\":0.8,\n",
        "    \"top_p\": 0.95,\n",
        "    \"max_new_tokens\" : 256,\n",
        "\n",
        "}\n",
        "tokenizer= AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "li = []\n",
        "start_time = time.time()\n",
        "for setence in prompts:\n",
        "  input_id = tokenizer.encode(setence, return_tensors=\"pt\").to('cuda')\n",
        "  output = model.generate(input_id,**myparams)\n",
        "  a = tokenizer.decode(output[0],skip_special_tokens=True)\n",
        "  li.append(a)\n",
        "for string in li:\n",
        "  print(string)\n",
        "  print()\n",
        "end_time = time.time()\n",
        "print(f\"걸린시간은 {end_time-start_time:.2f}초\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY_3VFuGI-NA",
        "outputId": "97539745-90b9-4e57-acfe-ed9552b4cd11"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, my name is Kelsie and I'm a 23 year old artist from the United States. I've been creating art for as long as I can remember, and I'm always looking for new ways to express myself and connect with others through my work. I've been drawing and painting for most of my life, but I've also experimented with other mediums like digital art, sculpture, and even filmmaking. I'm always open to new ideas and techniques, and I love to learn and grow as an artist. I'm excited to see where my passion for art takes me, and I hope to be able to share my work with others and inspire them in some way.\n",
            "\n",
            "The president of the United States is the head of the executive branch and the highest-ranking official in the federal government. The president is elected by the people through the Electoral College and serves a four-year term. The president's primary responsibilities include:\n",
            "\n",
            "\n",
            "1. Serving as the commander-in-chief of the armed forces\n",
            "2. Nominating and, with the advice and consent of the Senate, appointing federal judges, including Supreme Court justices\n",
            "3. Signing or vetoing bills passed by Congress\n",
            "4. Conducting foreign policy and negotiating treaties on behalf of the United States\n",
            "5. Appointing ambassadors and other high-ranking officials\n",
            "6. Making executive orders to carry out and enforce laws\n",
            "7. Addressing the nation and Congress on important issues\n",
            "8. Leading and coordinating the response to national emergencies and natural disasters\n",
            "9. Serving as the symbol of national unity and identity\n",
            "10. Ensuring that the federal government is accountable to the people through the system of checks and balances among the branches of government.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The capital of France is Paris, which is known for its beautiful architecture, art museums, fashion, and cuisine. Here are some of the best things to do in Paris:\n",
            "1. Visit the Eiffel Tower: The Eiffel Tower is one of the most iconic landmarks in Paris and offers stunning views of the city. You can take the elevator to the top for a panoramic view of the city.\n",
            "2. Explore the Louvre Museum: The Louvre Museum is one of the world's largest and most famous art museums, housing an impressive collection of art and artifacts from around the world, including the Mona Lisa.\n",
            "3. Stroll along the Seine River: The Seine River runs through the heart of Paris and offers beautiful views of the city's landmarks, bridges, and charming cafes and restaurants.\n",
            "4. Visit Notre Dame Cathedral: Notre Dame Cathedral is a beautiful and historic cathedral located on the Île de la Cité in the heart of Paris. It is known for its Gothic architecture and stunning stained glass windows.\n",
            "5. Take a Palace of Versailles Day Trip: The Palace of Vers\n",
            "\n",
            "The future of AI is in the hands of the next generation. Here are some of the most innovative and inspiring projects that showcase the creativity and potential of young AI talent:\n",
            "1. Neural Magic: Developed by 17-year-old AI enthusiasts from the UK, Neural Magic is an AI-powered platform that allows users to create personalized and interactive art using artificial intelligence.\n",
            "2. AI-generated Music: 19-year-old musician and AI enthusiast, Max Cuse Rød, has developed an AI system that can generate original and complex music compositions.\n",
            "3. AI-powered Fashion: 18-year-old designer, Lingzi Zhang, has created a clothing line that uses AI to generate unique and innovative designs.\n",
            "4. AI-controlled Robotics: 17-year-old robotics enthusiast, Jae Kim, has developed an AI-controlled robot that can navigate and interact with its environment.\n",
            "5. AI-based Games: 19-year-old game developer, Tetyana Lukyanenko, has created an AI-\n",
            "\n",
            "걸린시간은 48.55초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# del model\n",
        "# del tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "QLntihpzLPRq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fa = ['h', 'f', 'c', 'd']\n",
        "lif = []\n",
        "start = time.time()\n",
        "for text in fa:\n",
        "  lif.append(text)\n",
        "for text in lif:\n",
        "  print(text)\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz9eyvFCMVK1",
        "outputId": "bc997cff-e3fa-4199-e921-b50fe9ad732e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h\n",
            "f\n",
            "c\n",
            "d\n",
            "0.00029587745666503906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P-4VMFYTNZkG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzvNaHM8+hr28f5Ij9o/VL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}